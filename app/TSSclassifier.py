import pydoc

import pandas as pd
from enum import Enum
from json import loads, dumps
from app import GFFParser as ps
import re


class TSSType(Enum):
    PRIMARY = "pTSS/sTSS"
    INTERNAL = "iTSS"
    ANTISENSE = "asTSS"
    ORPHAN = "orphan"


def extract_gene_name(attributes):
    """
    Helper function for classify. Expects a string and extracts the substring after 'Name='.
    If this pattern is not found, the function returns None.
    :param attributes
    :return: gene name
    """
    match = re.search(r'Name=([^;]+)', attributes)
    return match.group(1) if match else None


class GffFormatException(Exception):
    """Exception raised when the GFF file format is incorrect"""
    pass


def classify(gff_df, TSS_list, strand):
    """
    Classifies TSS based on their position relative to genes in a GFF file.
    :param gff_df:  DataFrame containing information from a GFF file.
    :param TSS_list: a list of all predicted TSS
    :param strand: the strand on which the TSS were predicted(True for reverse and False for forward)
    :return: tss_classified: data frame that holds the position, classified type, and corresponding gene name of the TSS
    """
    #gff_df = ps.parse_gff_to_df(gff_df)

    tss_classified = {}
    gff_df['gene name'] = gff_df['attributes'].apply(extract_gene_name)

    if gff_df['gene name'].isnull().all():
        raise GffFormatException(
            "the attributes column of your GFF file does not contain gene names in the format 'Name=..")

    gene_names = []

    gff_fw = gff_df[(gff_df['strand'] == "+")]
    gff_rv = gff_df[(gff_df['strand'] == "-")]

    for tss in TSS_list:

        if not strand:
            intern = gff_fw[(gff_fw['end'] >= tss) & (gff_fw['start'] <= tss)]
            prim = gff_fw[(gff_fw['start'] >= tss) & (gff_fw['start'] - 200 <= tss)]
            anti = gff_rv[(gff_rv['end'] + 100 >= tss) & (gff_rv['start'] - 100 <= tss)]

        else:
            intern = gff_rv[(gff_rv['end'] >= tss) & (gff_rv['start'] <= tss)]
            prim = gff_rv[(gff_rv['start'] >= tss) & (gff_rv['start'] - 200 <= tss)]
            anti = gff_fw[(gff_fw['end'] + 100 >= tss) & (gff_fw['start'] - 100 <= tss)]

        possible_class = []

        if not intern.empty:
            possible_class.extend([TSSType.INTERNAL.value] * len(intern))
            gene_names.extend(intern['gene name'].tolist())

        if not prim.empty:
            possible_class.extend([TSSType.PRIMARY.value] * len(prim))
            gene_names.extend(prim['gene name'].tolist())

        if not anti.empty:
            possible_class.extend([TSSType.ANTISENSE.value] * len(anti))
            gene_names.extend(anti['gene name'].tolist())

        if len(possible_class) == 0:
            possible_class = [TSSType.ORPHAN.value]
            gene_names.append(None)

        tss_classified[tss] = possible_class

    data_tuples = [(k, tss_type) for k, v in tss_classified.items() for tss_type in v]

    tss_classified = pd.DataFrame(data_tuples, columns=['Pos', 'TSS type'])
    tss_classified['gene name'] = gene_names

    return tss_classified


def find_common_tss(prediction, master_table, strand):
    """
    Identifies common TSS detected by TSS Predator and our prediction.
    :param prediction:  DataFrame containing the position, type, and corresponding gene name of the predicted TSS
    :param master_table: DataFrame containing the master table data generated by TSS predator
    :param strand: the strand on which the TSS were predicted(True for reverse and False for forward)
    :return: common_tss_df: data frame that holds the position, type, and corresponding gene name of the TSS that were
    found by both TSS predator and our prediction
    """
    if not strand:
        mt_relevant_columns = master_table[master_table['Strand'] == '+']

    else:
        mt_relevant_columns = master_table[master_table['Strand'] == '-']

    mt_relevant_columns = mt_relevant_columns[['Pos', 'TSS type']].reset_index(drop=True)

    expanded_prediction = pd.concat([
        prediction.assign(**{'Pos': prediction['Pos'] + offset})
        for offset in range(-5, 6)
    ])

    common_tss_df = pd.merge(expanded_prediction, mt_relevant_columns, on=['Pos', 'TSS type'],
                             how='inner').drop_duplicates()

    return common_tss_df


def to_csv(prediction, common_tss, master_table, tss_list, confidence_list, strand):
    """
     creates 3 different files:
     - prediction.csv: Contains positions, types, confidence values, and gene names of our predicted TSS
     - shared_TSS.csv: Contains positions, types, and gene names of TSS found by both our prediction and TSS Predator
     - TSS_predator.csv: Contains positions and types of TSS found by TSS Predator
     :param prediction:  DataFrame containing the TSS predicted by us
     :param common_tss: DataFrame containing the TSS predicted by both us and TSS predator
     :param master_table: DataFrame containing the master table data generated by TSS predator
     :param tss_list: list of detected TSS
     :param confidence_list: list that assigns a confidence value to each of the TSS in tss_list
     :param strand: the strand on which the TSS were predicted(True for reverse and False for forward)
     :return: None
     """
    df = pd.DataFrame({'Pos': tss_list, 'confidence': confidence_list})
    prediction = pd.merge(df, prediction, on='Pos', how='inner')
    columns_order = ['Pos', 'TSS type', 'confidence', 'gene name']
    prediction = prediction[columns_order]

    if not strand:
        mt_relevant_columns = master_table[master_table['Strand'] == '+']

    else:
        mt_relevant_columns = master_table[master_table['Strand'] == '-']

    mt_relevant_columns = mt_relevant_columns[['Pos', 'TSS type']]

    dfs = [(prediction, 'prediction'), (common_tss, 'shared_TSS'), (mt_relevant_columns, 'TSS_predator')]

    for df, name in dfs:
        csv_file = f'{name}.csv'
        with open(csv_file, 'w', newline='') as f:
            df.to_csv(f, index=False)


# fehler wenn df leer ist
def calculate_frequency_of_tss_classes(common_tss_df):
    type_counts = common_tss_df['TSS type'].value_counts()
    all_types = [e.value for e in TSSType]
    type_counts = type_counts.reindex(all_types, fill_value=0)
    total_count = type_counts.sum()
    relative_frequencies = type_counts / total_count

    return relative_frequencies


def recall_and_precision_return_obj(common_tss_df, prediction_df, master_table_df):
    result_dict = {"recall": len(common_tss_df.index) / len(master_table_df.index),
                   "precision": len(common_tss_df.index) / len(prediction_df.index)}
    result_json = loads(dumps(result_dict))
    return result_json


def freq_return_obj(common_tss_df, prediction_df, master_table_df):
    result_dict = {'common_tss': calculate_frequency_of_tss_classes(common_tss_df).to_dict(),
                   'prediction': calculate_frequency_of_tss_classes(prediction_df).to_dict(),
                   'TSS_predator': calculate_frequency_of_tss_classes(master_table_df).to_dict()}
    result_json = loads(dumps(result_dict))
    return result_json

'''
mt = {
    'Pos': [25675, 31366, 31650, 32000, 405, 400],
    'TSS type': ["iTSS", "asTSS", "pTSS/sTSS", "asTSS", "iTSS", "pTSS/sTSS"],
    'detected': ['1', '1', '1', '0', '1', '1'],
    'Locus_tag': ['esdnc', 'aada', 'Wqwq', 'wwisd', 'wwisd', 'wwisd'],
    'Strand': ["+", "-", "+", "+", "+", "+"]
}

df = pd.DataFrame(mt)

cl = classify("../tests/test_files/NC_004703.gff", [400, 25675, 31362, 31650], False)
print(cl)
co = find_common_tss(cl, df, False)
print(co)
to_csv(cl, co, df, [400, 25675, 31362, 31650], [0.9, 0.5, 0.7, 0.8], False)

#print(freq_return_obj(cl, co, df))
#print(recall_and_precision_return_obj(co, cl, df))'''
